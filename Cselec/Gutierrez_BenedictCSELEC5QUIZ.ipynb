{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4389e58-98b9-4e2a-8016-614d30ce23a0",
   "metadata": {},
   "source": [
    "## **Activity**: Build and Train a Neural Network for a Custom Dataset\n",
    "### **Objective**: In this activity, you’ll create, train, and evaluate a neural network for a binary classification problem using either PyTorch or TensorFlow (your choice). The goal is to apply the concepts learned, such as model building, activation functions, loss functions, and optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0be64-6308-4910-aa7f-46bb1eb349d0",
   "metadata": {},
   "source": [
    "# Dataset Creation\n",
    "## **Step 1:** Generate a custom dataset using Python's sklearn.datasets or create synthetic data. The dataset should contain at least two classes (for binary classification) and multiple features.\n",
    "\n",
    "## **Step 2: Load a Dataset (e.g., Breast Cancer Dataset // from sklearn.datasets import load_breast_cancer)**\n",
    "\n",
    "## **Step 3:Choose a Framework**\n",
    "### Select either PyTorch or TensorFlow/Keras to implement your neural network.\n",
    "\n",
    "## **Step 4:**\n",
    "### Build the Neural Network\n",
    "### Define a neural network architecture with:\n",
    "### Input layer based on the number of features in the dataset.\n",
    "### At least one hidden layer with a non-linear activation function (e.g., ReLU).\n",
    "### Output layer with a sigmoid activation for binary classification.\n",
    "\n",
    "## **Step 5:Compile the Model**\n",
    "### Define the loss function (Binary Cross-Entropy) and the optimizer (Adam).\n",
    "\n",
    "## **Step 6:Training the Model**\n",
    "### Split the dataset into training and testing sets (80/20 split) using sklearn.model_selection.train_test_split.\n",
    "### Train the model over multiple epochs.\n",
    "\n",
    "## **Step 7:Evaluate the Model**\n",
    "### Use the test set to evaluate the performance of your model.\n",
    "\n",
    "## **Step 8:Tuning and Experimentation**\n",
    "### Experiment with different hyperparameters like:\n",
    "\n",
    "####    Number of hidden layers.\n",
    "####    Number of neurons in each layer.\n",
    "####    Learning rate.\n",
    "####    Batch size.\n",
    "####    Track how these changes affect model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c718c03-edce-466c-a500-bc7a4a892358",
   "metadata": {},
   "source": [
    "## **Deliverables:**\n",
    "### **Python code for:**\n",
    "#### Neural network model definition.\n",
    "#### Model training and evaluation.\n",
    "### **A report describing:**\n",
    "#### The architecture chosen for your neural network.\n",
    "#### The dataset used and its characteristics.\n",
    "#### Key observations from tuning hyperparameters (number of layers, neurons, learning rate, etc.).\n",
    "#### The final model's accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d67755-4c34-4015-aebb-a22ece833504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/390.3 MB 8.4 MB/s eta 0:00:47\n",
      "   ---------------------------------------- 3.7/390.3 MB 10.4 MB/s eta 0:00:38\n",
      "    --------------------------------------- 6.0/390.3 MB 10.9 MB/s eta 0:00:36\n",
      "    --------------------------------------- 8.4/390.3 MB 11.1 MB/s eta 0:00:35\n",
      "    --------------------------------------- 9.4/390.3 MB 9.8 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 11.3/390.3 MB 9.4 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 13.1/390.3 MB 9.3 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 14.7/390.3 MB 9.0 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 16.5/390.3 MB 9.0 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 18.9/390.3 MB 9.2 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 21.0/390.3 MB 9.3 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 23.3/390.3 MB 9.4 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 25.4/390.3 MB 9.5 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 27.8/390.3 MB 9.7 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 30.1/390.3 MB 9.8 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 32.2/390.3 MB 9.8 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 34.3/390.3 MB 9.9 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 34.6/390.3 MB 9.6 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 37.2/390.3 MB 9.6 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 39.6/390.3 MB 9.6 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 41.4/390.3 MB 9.6 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 43.8/390.3 MB 9.7 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 45.4/390.3 MB 9.7 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 47.7/390.3 MB 9.7 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 50.1/390.3 MB 9.8 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 52.2/390.3 MB 9.8 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 54.0/390.3 MB 9.8 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 56.1/390.3 MB 9.8 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 57.9/390.3 MB 9.8 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 60.3/390.3 MB 9.8 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 62.9/390.3 MB 9.9 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 65.3/390.3 MB 9.9 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 67.4/390.3 MB 9.9 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 68.7/390.3 MB 9.9 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 71.0/390.3 MB 9.9 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 73.4/390.3 MB 9.9 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 75.8/390.3 MB 10.0 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 78.4/390.3 MB 10.0 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 80.7/390.3 MB 10.0 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 82.8/390.3 MB 10.1 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 84.9/390.3 MB 10.1 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 87.3/390.3 MB 10.1 MB/s eta 0:00:31\n",
      "   --------- ------------------------------ 89.1/390.3 MB 10.1 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 89.9/390.3 MB 10.0 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 93.1/390.3 MB 10.0 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 95.4/390.3 MB 10.0 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 97.8/390.3 MB 10.1 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 99.9/390.3 MB 10.1 MB/s eta 0:00:29\n",
      "   ---------- ---------------------------- 102.2/390.3 MB 10.1 MB/s eta 0:00:29\n",
      "   ---------- ---------------------------- 104.1/390.3 MB 10.1 MB/s eta 0:00:29\n",
      "   ---------- ---------------------------- 106.4/390.3 MB 10.1 MB/s eta 0:00:29\n",
      "   ---------- ---------------------------- 108.3/390.3 MB 10.1 MB/s eta 0:00:28\n",
      "   ----------- --------------------------- 110.4/390.3 MB 10.1 MB/s eta 0:00:28\n",
      "   ----------- --------------------------- 111.9/390.3 MB 10.1 MB/s eta 0:00:28\n",
      "   ----------- --------------------------- 113.8/390.3 MB 10.0 MB/s eta 0:00:28\n",
      "   ----------- --------------------------- 115.6/390.3 MB 10.0 MB/s eta 0:00:28\n",
      "   ----------- --------------------------- 117.2/390.3 MB 10.0 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 119.0/390.3 MB 9.9 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 120.3/390.3 MB 9.9 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 121.9/390.3 MB 9.9 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 123.5/390.3 MB 9.8 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 124.8/390.3 MB 9.8 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 126.4/390.3 MB 9.7 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 127.9/390.3 MB 9.7 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 129.2/390.3 MB 9.7 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 130.8/390.3 MB 9.6 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 131.9/390.3 MB 9.6 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 133.4/390.3 MB 9.5 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 134.0/390.3 MB 9.4 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 135.5/390.3 MB 9.4 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 136.8/390.3 MB 9.4 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 138.1/390.3 MB 9.3 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 139.2/390.3 MB 9.3 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 140.5/390.3 MB 9.2 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 141.8/390.3 MB 9.2 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 143.4/390.3 MB 9.2 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 145.2/390.3 MB 9.1 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 146.8/390.3 MB 9.1 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 148.4/390.3 MB 9.1 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 149.7/390.3 MB 9.1 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 151.0/390.3 MB 9.0 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 152.0/390.3 MB 9.0 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 153.1/390.3 MB 8.9 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 154.1/390.3 MB 8.9 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 155.5/390.3 MB 8.9 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 156.2/390.3 MB 8.8 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 156.8/390.3 MB 8.7 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 157.5/390.3 MB 8.7 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 158.3/390.3 MB 8.6 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 159.1/390.3 MB 8.6 MB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 160.4/390.3 MB 8.5 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 161.5/390.3 MB 8.5 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 162.8/390.3 MB 8.5 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 163.8/390.3 MB 8.4 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 165.2/390.3 MB 8.4 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 166.5/390.3 MB 8.4 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 167.5/390.3 MB 8.3 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 168.3/390.3 MB 8.3 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 169.3/390.3 MB 8.3 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 170.4/390.3 MB 8.2 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 171.4/390.3 MB 8.2 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 172.2/390.3 MB 8.2 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 173.3/390.3 MB 8.1 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 174.1/390.3 MB 8.1 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 175.1/390.3 MB 8.1 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 176.2/390.3 MB 8.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 177.2/390.3 MB 8.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 178.3/390.3 MB 8.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 179.3/390.3 MB 8.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 180.1/390.3 MB 7.9 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 180.9/390.3 MB 7.9 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 181.9/390.3 MB 7.8 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 182.7/390.3 MB 7.8 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 183.8/390.3 MB 7.8 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 185.1/390.3 MB 7.8 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 186.4/390.3 MB 7.8 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 187.4/390.3 MB 7.7 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 188.2/390.3 MB 7.7 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 189.3/390.3 MB 7.7 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 190.1/390.3 MB 7.7 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 190.8/390.3 MB 7.6 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 191.6/390.3 MB 7.6 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 192.4/390.3 MB 7.6 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 192.9/390.3 MB 7.5 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 193.5/390.3 MB 7.5 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 194.0/390.3 MB 7.5 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 194.5/390.3 MB 7.4 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 195.3/390.3 MB 7.4 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 195.8/390.3 MB 7.3 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 196.3/390.3 MB 7.3 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 197.1/390.3 MB 7.3 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 197.9/390.3 MB 7.2 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 198.4/390.3 MB 7.2 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 199.2/390.3 MB 7.2 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 200.0/390.3 MB 7.1 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 200.8/390.3 MB 7.1 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 201.3/390.3 MB 7.1 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 202.1/390.3 MB 7.1 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 202.9/390.3 MB 7.0 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 203.7/390.3 MB 7.0 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 204.5/390.3 MB 7.0 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 205.3/390.3 MB 7.0 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 206.3/390.3 MB 7.0 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 207.1/390.3 MB 6.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 207.9/390.3 MB 6.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 208.9/390.3 MB 6.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 209.7/390.3 MB 6.8 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 210.8/390.3 MB 6.8 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 211.6/390.3 MB 6.8 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 212.3/390.3 MB 6.7 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 213.1/390.3 MB 6.7 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 214.2/390.3 MB 6.7 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 215.2/390.3 MB 6.7 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 216.0/390.3 MB 6.6 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 217.1/390.3 MB 6.6 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 218.1/390.3 MB 6.5 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 219.2/390.3 MB 6.5 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 220.2/390.3 MB 6.5 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 221.2/390.3 MB 6.4 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 222.6/390.3 MB 6.4 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 223.3/390.3 MB 6.3 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 224.7/390.3 MB 6.4 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 225.7/390.3 MB 6.3 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 226.8/390.3 MB 6.3 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 227.5/390.3 MB 6.2 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 228.6/390.3 MB 6.2 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 229.6/390.3 MB 6.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 230.7/390.3 MB 6.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 232.0/390.3 MB 6.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 233.0/390.3 MB 6.0 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 234.4/390.3 MB 6.0 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 235.7/390.3 MB 6.0 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 236.5/390.3 MB 6.0 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 237.5/390.3 MB 5.9 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 238.6/390.3 MB 5.9 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 239.6/390.3 MB 5.8 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 240.6/390.3 MB 5.8 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 241.7/390.3 MB 5.8 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 243.0/390.3 MB 5.7 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 244.3/390.3 MB 5.7 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 245.1/390.3 MB 5.7 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 246.4/390.3 MB 5.6 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 247.7/390.3 MB 5.6 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 249.0/390.3 MB 5.6 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 250.3/390.3 MB 5.5 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 251.7/390.3 MB 5.5 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 253.0/390.3 MB 5.5 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 254.3/390.3 MB 5.5 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 255.9/390.3 MB 5.4 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 257.2/390.3 MB 5.4 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 258.5/390.3 MB 5.4 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 259.8/390.3 MB 5.3 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 261.4/390.3 MB 5.3 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 262.4/390.3 MB 5.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 263.5/390.3 MB 5.2 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 264.5/390.3 MB 5.2 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 265.8/390.3 MB 5.2 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 266.9/390.3 MB 5.2 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 267.9/390.3 MB 5.1 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 268.7/390.3 MB 5.1 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 269.7/390.3 MB 5.1 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 270.8/390.3 MB 5.1 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 271.6/390.3 MB 5.0 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 272.6/390.3 MB 5.0 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 273.4/390.3 MB 5.0 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 274.5/390.3 MB 5.0 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 275.3/390.3 MB 4.9 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 276.0/390.3 MB 4.9 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 277.1/390.3 MB 4.9 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 278.1/390.3 MB 4.9 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 279.2/390.3 MB 4.9 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 280.0/390.3 MB 4.9 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 281.0/390.3 MB 4.9 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 282.1/390.3 MB 4.9 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 283.1/390.3 MB 4.9 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 284.2/390.3 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 284.7/390.3 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 285.7/390.3 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 286.8/390.3 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 287.8/390.3 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 288.9/390.3 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 290.2/390.3 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 291.2/390.3 MB 4.7 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 292.6/390.3 MB 4.7 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 293.6/390.3 MB 4.7 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 294.9/390.3 MB 4.7 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 296.0/390.3 MB 4.7 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 297.0/390.3 MB 4.7 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 298.3/390.3 MB 4.8 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 299.4/390.3 MB 4.8 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 300.7/390.3 MB 4.8 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 302.0/390.3 MB 4.8 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 303.3/390.3 MB 4.8 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 304.6/390.3 MB 4.8 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 306.2/390.3 MB 4.8 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 307.5/390.3 MB 4.8 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 308.8/390.3 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 310.4/390.3 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 311.7/390.3 MB 4.9 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 313.0/390.3 MB 4.9 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 314.6/390.3 MB 4.9 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 315.6/390.3 MB 4.9 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 316.7/390.3 MB 4.9 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 318.2/390.3 MB 4.9 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 319.6/390.3 MB 4.9 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 320.9/390.3 MB 4.9 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 322.4/390.3 MB 5.0 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 324.0/390.3 MB 5.0 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 325.8/390.3 MB 5.0 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 327.4/390.3 MB 5.0 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 329.0/390.3 MB 5.0 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 330.6/390.3 MB 5.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 332.1/390.3 MB 5.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 333.7/390.3 MB 5.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 335.3/390.3 MB 5.1 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 336.6/390.3 MB 5.1 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 338.4/390.3 MB 5.2 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 340.3/390.3 MB 5.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 342.1/390.3 MB 5.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 343.9/390.3 MB 5.2 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 345.8/390.3 MB 5.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 347.6/390.3 MB 5.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 349.7/390.3 MB 5.3 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 351.3/390.3 MB 5.4 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 353.4/390.3 MB 5.4 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 355.5/390.3 MB 5.5 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 357.0/390.3 MB 5.5 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 358.9/390.3 MB 5.5 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 360.7/390.3 MB 5.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 362.5/390.3 MB 5.6 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 364.6/390.3 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 366.7/390.3 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 368.8/390.3 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 370.9/390.3 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 372.8/390.3 MB 5.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 374.9/390.3 MB 5.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 376.7/390.3 MB 5.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 379.3/390.3 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  381.4/390.3 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  383.3/390.3 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  385.1/390.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  387.2/390.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  389.0/390.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 390.3/390.3 MB 6.0 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.1/4.3 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.3 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 2.1/3.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 9.7 MB/s eta 0:00:00\n",
      "Using cached keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.1/15.6 MB 9.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.2/15.6 MB 10.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.0/15.6 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.1/15.6 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.4/15.6 MB 9.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.5/15.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.4/15.6 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 8.7 MB/s eta 0:00:00\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 8.6 MB/s eta 0:00:00\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-win_amd64.whl (283 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 h5py-3.12.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.0 protobuf-5.28.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190b7f97-1b2f-4756-aefa-ef5d52930d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ben\\anaconda3\\envs\\cselec5\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.0 MB 6.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.0 MB 8.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.8/11.0 MB 9.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.0 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 9.7 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f27983-cd3f-49e2-b00a-2d3fc5d3ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35926c24-2853-4f74-b604-7ed9f754099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ben\\anaconda3\\envs\\CSELEC5\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m930\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m465\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411</span> (5.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,411\u001b[0m (5.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411</span> (5.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,411\u001b[0m (5.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Dense(30, input_dim=X_train.shape[1], activation='relu'),  # Input layer and first hidden layer\n",
    "    Dense(15, activation='relu'),  # Second hidden layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9fd5b62-c9fc-4e57-985e-472fb830843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffdef6df-0315-4426-b2b5-d521a849f702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0199 - val_accuracy: 0.9737 - val_loss: 0.0731\n",
      "Epoch 2/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0400 - val_accuracy: 0.9737 - val_loss: 0.0756\n",
      "Epoch 3/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0265 - val_accuracy: 0.9737 - val_loss: 0.0741\n",
      "Epoch 4/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0309 - val_accuracy: 0.9737 - val_loss: 0.0750\n",
      "Epoch 5/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0204 - val_accuracy: 0.9737 - val_loss: 0.0756\n",
      "Epoch 6/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0296 - val_accuracy: 0.9737 - val_loss: 0.0755\n",
      "Epoch 7/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0295 - val_accuracy: 0.9737 - val_loss: 0.0750\n",
      "Epoch 8/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0244 - val_accuracy: 0.9825 - val_loss: 0.0745\n",
      "Epoch 9/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0178 - val_accuracy: 0.9737 - val_loss: 0.0753\n",
      "Epoch 10/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0234 - val_accuracy: 0.9737 - val_loss: 0.0761\n",
      "Epoch 11/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0215 - val_accuracy: 0.9825 - val_loss: 0.0765\n",
      "Epoch 12/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0190 - val_accuracy: 0.9825 - val_loss: 0.0773\n",
      "Epoch 13/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0167 - val_accuracy: 0.9825 - val_loss: 0.0774\n",
      "Epoch 14/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0139 - val_accuracy: 0.9825 - val_loss: 0.0775\n",
      "Epoch 15/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0276 - val_accuracy: 0.9825 - val_loss: 0.0762\n",
      "Epoch 16/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0157 - val_accuracy: 0.9825 - val_loss: 0.0765\n",
      "Epoch 17/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0186 - val_accuracy: 0.9825 - val_loss: 0.0776\n",
      "Epoch 18/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0187 - val_accuracy: 0.9825 - val_loss: 0.0795\n",
      "Epoch 19/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0129 - val_accuracy: 0.9825 - val_loss: 0.0787\n",
      "Epoch 20/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0149 - val_accuracy: 0.9825 - val_loss: 0.0803\n",
      "Epoch 21/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0160 - val_accuracy: 0.9825 - val_loss: 0.0801\n",
      "Epoch 22/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0164 - val_accuracy: 0.9825 - val_loss: 0.0810\n",
      "Epoch 23/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0099 - val_accuracy: 0.9825 - val_loss: 0.0803\n",
      "Epoch 24/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0216 - val_accuracy: 0.9825 - val_loss: 0.0813\n",
      "Epoch 25/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0163 - val_accuracy: 0.9825 - val_loss: 0.0780\n",
      "Epoch 26/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0110 - val_accuracy: 0.9825 - val_loss: 0.0798\n",
      "Epoch 27/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0084 - val_accuracy: 0.9825 - val_loss: 0.0805\n",
      "Epoch 28/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0086 - val_accuracy: 0.9825 - val_loss: 0.0793\n",
      "Epoch 29/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0096 - val_accuracy: 0.9825 - val_loss: 0.0881\n",
      "Epoch 30/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0106 - val_accuracy: 0.9825 - val_loss: 0.0849\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7dbb73-fd76-46d5-8837-fc9df8b31fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.1037\n",
      "Test Accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23983e70-c482-4d85-9d52-546789501f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8165 - loss: 0.5815 - val_accuracy: 0.9211 - val_loss: 0.4473\n",
      "Epoch 2/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.4194 - val_accuracy: 0.9474 - val_loss: 0.2949\n",
      "Epoch 3/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2797 - val_accuracy: 0.9561 - val_loss: 0.1836\n",
      "Epoch 4/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.1870 - val_accuracy: 0.9649 - val_loss: 0.1222\n",
      "Epoch 5/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.1192 - val_accuracy: 0.9737 - val_loss: 0.0919\n",
      "Epoch 6/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0937 - val_accuracy: 0.9825 - val_loss: 0.0783\n",
      "Epoch 7/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 0.0926 - val_accuracy: 0.9737 - val_loss: 0.0764\n",
      "Epoch 8/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0682 - val_accuracy: 0.9737 - val_loss: 0.0767\n",
      "Epoch 9/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0695 - val_accuracy: 0.9649 - val_loss: 0.0668\n",
      "Epoch 10/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0496 - val_accuracy: 0.9649 - val_loss: 0.0648\n",
      "Epoch 11/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0449 - val_accuracy: 0.9649 - val_loss: 0.0684\n",
      "Epoch 12/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0482 - val_accuracy: 0.9649 - val_loss: 0.0664\n",
      "Epoch 13/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0390 - val_accuracy: 0.9737 - val_loss: 0.0639\n",
      "Epoch 14/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0622 - val_accuracy: 0.9737 - val_loss: 0.0715\n",
      "Epoch 15/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0449 - val_accuracy: 0.9737 - val_loss: 0.0637\n",
      "Epoch 16/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0346 - val_accuracy: 0.9737 - val_loss: 0.0664\n",
      "Epoch 17/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0301 - val_accuracy: 0.9825 - val_loss: 0.0678\n",
      "Epoch 18/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0280 - val_accuracy: 0.9825 - val_loss: 0.0688\n",
      "Epoch 19/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0283 - val_accuracy: 0.9825 - val_loss: 0.0700\n",
      "Epoch 20/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0169 - val_accuracy: 0.9825 - val_loss: 0.0721\n",
      "Epoch 21/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0239 - val_accuracy: 0.9825 - val_loss: 0.0712\n",
      "Epoch 22/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0158 - val_accuracy: 0.9825 - val_loss: 0.0755\n",
      "Epoch 23/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0126 - val_accuracy: 0.9825 - val_loss: 0.0771\n",
      "Epoch 24/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0202 - val_accuracy: 0.9825 - val_loss: 0.0796\n",
      "Epoch 25/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0215 - val_accuracy: 0.9737 - val_loss: 0.0809\n",
      "Epoch 26/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0105 - val_accuracy: 0.9825 - val_loss: 0.0848\n",
      "Epoch 27/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0205 - val_accuracy: 0.9737 - val_loss: 0.0834\n",
      "Epoch 28/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0129 - val_accuracy: 0.9737 - val_loss: 0.0864\n",
      "Epoch 29/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0128 - val_accuracy: 0.9737 - val_loss: 0.0866\n",
      "Epoch 30/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0102 - val_accuracy: 0.9737 - val_loss: 0.0895\n"
     ]
    }
   ],
   "source": [
    "# Changing the number of neurons and hidden layers\n",
    "model = Sequential([\n",
    "    Dense(50, input_dim=X_train.shape[1], activation='relu'),  # Input layer and first hidden layer\n",
    "    Dense(25, activation='relu'),  # Second hidden layer\n",
    "    Dense(10, activation='relu'),  # Third hidden layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9faac26-1a4c-46d3-bbc5-1bdd73294a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
